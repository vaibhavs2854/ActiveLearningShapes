{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7649d85",
   "metadata": {},
   "source": [
    "# Active Learning Experiment Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b8615a",
   "metadata": {},
   "source": [
    "##### TODO\n",
    "if using autooracle, want \n",
    "- visualization of what the oracle is seeing/saying\n",
    "\n",
    "in general want\n",
    "- training curves (make sure to maintain a history from initial training)\n",
    "\n",
    "convergence criterion? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19bb0a",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14439226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python Library imports\n",
    "import random\n",
    "import torch \n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import datetime \n",
    "\n",
    "\n",
    "#Backend py file imports\n",
    "from dataloader import get_DataLoader\n",
    "from disc_model import disc_model\n",
    "\n",
    "from auto_oracle import query_oracle_automatic\n",
    "# from manual_oracle import query_oracle\n",
    "\n",
    "from experiment import save_active_learning_results, remove_bad_oracle_results\n",
    "from experiment import update_dir_with_oracle_info, redirect_saved_oracle_filepaths_to_thresheld_directory, save_files_for_nnunet\n",
    "\n",
    "from nnunet_model import convert_2d_image_to_nifti, plan_and_preprocess\n",
    "import nnunet_model\n",
    "import unet_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edeaaa9",
   "metadata": {},
   "source": [
    "### Seed all Random Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed_number = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bead1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(random_seed_number)\n",
    "torch.cuda.manual_seed(random_seed_number)\n",
    "np.random.seed(random_seed_number)\n",
    "random.seed(random_seed_number)\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1fa99",
   "metadata": {},
   "source": [
    "### Run ID Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a38565",
   "metadata": {},
   "source": [
    "This section will set up a run_id to identify each run and a save folder to save data to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc7b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_id has format of \"yy_mm_dd\", and iter_num is the current run on the day (0,1,2,etc)\n",
    "run_id = datetime.date.today().strftime(\"%y_%m_%d\")\n",
    "iter_num = input(\"which iteration is this of the day? \")\n",
    "\n",
    "# Where do you want to save all outputs?\n",
    "output_dir = \"/usr/xtmp/jly16/mammoproj/nnunet_integration_tmp/AllOracleRuns\"\n",
    "run_dir = os.path.join(output_dir, \"Run_\" + run_id, \"Iter\" + str(iter_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#users_name tells us who is working on the notebook (vaibhav/alina/julia)\n",
    "users_name = input(\"what is your name: \")\n",
    "print(f\"Your name is: {users_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d096d",
   "metadata": {},
   "source": [
    "## Active Learning Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d0540",
   "metadata": {},
   "source": [
    "### Set Image Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77ce113",
   "metadata": {},
   "source": [
    "This section sets up directories for the active learning. We will need a directory of images for training the discriminator, a directory that the oracle will query from, and a directory that has the ground truth segmentations.\n",
    "\n",
    "All files within the directories should be .npy and have shape (2, r, c) where the first channel is the original image, and the second channel is the binarized segmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdce43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_training_dir = \"/usr/xtmp/vs196/mammoproj/Data/final_dataset/train/\" \n",
    "oracle_query_dir = \"/usr/xtmp/vs196/mammoproj/Data/final_dataset/train/\" \n",
    "ground_truth_dir = \"/usr/xtmp/vs196/mammoproj/Data/final_dataset/train/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b3f859",
   "metadata": {},
   "source": [
    "### Initial Discriminator Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bc7a46",
   "metadata": {},
   "source": [
    "In this section, we initialize the discriminator by training a VGG11 network to discriminate between \"good\" segmentations (labeled `1`) and \"bad\" segmentations (labeled `0`). The data for training comes from the `discriminator_training_dir` specified [above](#Set-Image-Directories), but mismatches the (`image`, `segmentation`) pairs for half of each batch. The mismatched pairs get a label of `0`, the not mismatched pairs get a label of `1`.  \n",
    "\n",
    "Parameters that can be tuned: \n",
    "- `batch_size`\n",
    "- `init_disc_epochs` (number of epochs trained for initializing the discriminator)\n",
    "\n",
    "Mismatch method can be found in the `disc_model.initialize_model` method. This method may also warrant tweaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3bf868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates dataloader to churn out batches of the images from discriminator_training_dir. \n",
    "# Takes in batch_size and num_workers\n",
    "batch_size = 32 # TUNABLE PARAMETER\n",
    "dataloader = get_DataLoader(discriminator_training_dir, batch_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38518cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate, load, and initialize discriminator model by training N epochs (see disc_model.initialize_model for details)\n",
    "discriminator = disc_model()\n",
    "discriminator.load_model(dataloader) \n",
    "\n",
    "init_disc_epochs = 10 # TUNABLE PARAMETER\n",
    "discriminator.initialize_model(batch_size = batch_size, epochs=init_disc_epochs) # initial training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5651d24b",
   "metadata": {},
   "source": [
    "#### Take a look at initial discriminator training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.plot_loss() ## TODO: should this be by epoch instead?... why was it by batch initially? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02005797",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.plot_distribution(discriminator_training_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.show_disc(discriminator_training_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6869b43e",
   "metadata": {},
   "source": [
    "### Generating initial patient scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87486aa",
   "metadata": {},
   "source": [
    "Here, we get an score from the initialized discriminator for all (`image`, `segmentation`) pairs in the `oracle_query_dir`. The score indicates how good/bad the pair (low scores mean the segmentation does not match the image well, high scores mean the segmentation matches the image well). These scores will be used to choose which images to show the oracle. \n",
    "\n",
    "Note: it needs to use the same `batch_size` as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a holder for all patient scores (this will be a list of dictionaries)\n",
    "all_patient_scores = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e24d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the patient scores based on initial trained discriminator model. \n",
    "# Patient scores is how \"good\" the discriminator model thinks the segmentation is\n",
    "# patient_scores is a dictionary of patient:score which gets appended to the all_patient_scores list\n",
    "\n",
    "patient_dataloader = get_DataLoader(oracle_query_dir, batch_size, 2)\n",
    "patient_scores = discriminator.get_scores(patient_dataloader)  \n",
    "\n",
    "all_patient_scores.append(patient_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dd0986",
   "metadata": {},
   "source": [
    "### Oracle Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd2540",
   "metadata": {},
   "source": [
    "This section queries the oracle by selecting some (`image`, `segmentation`) pairs to show the oracle, and then the oracle provides feedback on whether the the segmentation is good (`1`), bad (`0`), or needs a new threshold (for clear over- or under-segmentation). The feedback from the oracle is the used to further train the discriminator. \n",
    "\n",
    "The method the system uses to select which pairs to show the oracle is specified using `query_method`. Currently, the method options are `\"uniform\"`, `\"best\"`, `\"worst\"`, `\"percentile=0.x\"` (where you specify a percentile), `\"random\"`, `\"middle\"`. These methods refer to the patient scores generated by the discriminator (eg \"best\" are the pairs with the highest discriminator score). \n",
    "\n",
    "The oracle can either be a human or the computer. When using a human oracle, we will want to use the `query_oracle` (may need some debugging). When using the computer oracle (aka auto-oracle), use `query_oracle_automatic`. Here, we use the auto-oracle. \n",
    "\n",
    "A major part of this research project is to see how the AL system reacts to different query methods and number of images queried. \n",
    "\n",
    "This process of querying and updating the discriminator can be repeated until the discriminator performs satisfactorily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90396e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializes oracle results dict and thresholds dict\n",
    "oracle_results = {}\n",
    "oracle_results_thresholds = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecdab2a",
   "metadata": {},
   "source": [
    "#### chk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0561fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOU SHOULD CHOOSE THE QUERY METHOD AND QUERY_NUMBER\n",
    "#      query_method: how it chooses the images to show. (best, worst, percentile=0.x, uniform)\n",
    "#      query_number: how many images to query at once\n",
    "\n",
    "# oracle_results is a dictionary that stores image_name:result. The result is 1 if correct, 0 if bad\n",
    "# oracle_results_thresholds is the threshold that produced the best segmentation \n",
    "\n",
    "_,_ = query_oracle_automatic(oracle_results, oracle_results_thresholds, patient_scores,\n",
    "                ground_truth_dir, oracle_query_dir,\n",
    "                query_method=\"uniform\", query_number=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d8ef85",
   "metadata": {},
   "source": [
    "### Updating the Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25735a26",
   "metadata": {},
   "source": [
    "Once the oracle has been queried, we want to update the discriminator by training it on the (`image`, `segmentation`) pairs and their good(`1`)/bad(`0`) labels. \n",
    "\n",
    "You can tune: \n",
    "- `update_disc_epochs`: how many epochs we update the discriminator with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d854584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the discriminator with data from the oracle for N number of epochs\n",
    "update_disc_epochs = 1 ## TUNABLE PARAMETER\n",
    "    \n",
    "discriminator.update_model(oracle_results,batch_size = batch_size, num_epochs= update_disc_epochs)\n",
    "patient_scores = discriminator.get_scores(patient_dataloader)\n",
    "all_patient_scores.append(patient_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c3084",
   "metadata": {},
   "source": [
    "#### Visualize discriminator post-update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b2ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.plot_distribution(discriminator_training_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a2b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.show_disc(discriminator_training_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7d44e7",
   "metadata": {},
   "source": [
    "# Go back to CK1 heading if you want to keep querying images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28912fc",
   "metadata": {},
   "source": [
    "### Deal with some file saving/organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11acd87b",
   "metadata": {},
   "source": [
    "This section saves some of the results from the discriminator section of our AL. It \n",
    "1. saves the pairs identified as good (ie correct segmentations) into the `CorrectSegmentations` subfolder of our `run_dir` (their paths are specified in `saved_oracle_filepaths`).\n",
    "2. creates a `OracleThresholdedImage_ff` subfolder that has all the same images from the `oracle_query_dir` with rethresholded segmentations based off `oracle_results_thresholds`.\n",
    "3. `new_saved_oracle_filepaths` are the pairs that were identified as good, but with their paths in the `OracleThresholdedImage_ff` subfolder\n",
    "4. IF we are using nnunet, then we need to redirect the `new_saved_oracle_filepaths` again, and reprocess to nnunet file/folder format which can be identified using an auto-generated nnunet `task_id` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad187bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for saving oracle results and pickling data structures\n",
    "saved_oracle_filepaths = save_active_learning_results(\n",
    "    run_dir, oracle_results, oracle_results_thresholds, oracle_query_dir)\n",
    "\n",
    "# # not necessary as oracle_results is never even used again in this method.\n",
    "# oracle_results = remove_bad_oracle_results(oracle_results)\n",
    "\n",
    "# if no images are classified as correct by oracle, print and return\n",
    "if len(saved_oracle_filepaths) == 0:\n",
    "    print(\"No oracle results classified as correct.\")\n",
    "else:\n",
    "    print(\n",
    "        f\"Oracle classifies {len(saved_oracle_filepaths)} images as correct.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e319c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter_train_dir = update_dir_with_oracle_info(run_dir, oracle_results_thresholds, oracle_query_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_saved_oracle_filepaths = redirect_saved_oracle_filepaths_to_thresheld_directory(\n",
    "    saved_oracle_filepaths, segmenter_train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c44ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ffb6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not unet: \n",
    "    last_task = sorted(glob.glob(os.path.join(os.environ['nnUNet_raw_data_base'], 'nnUNet_raw_data','Task*')))[-1]\n",
    "    last_task = last_task.split('nnUNet_raw_data/Task')[-1][:3]\n",
    "    task_id = int(last_task) + 1\n",
    "    save_files_for_nnunet(task_id, run_id, new_saved_oracle_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12924f02",
   "metadata": {},
   "source": [
    "### Update Segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd6b9a",
   "metadata": {},
   "source": [
    "In this section, we update the segmenter (which has been pre-trained off CBIS-DDSM) using the good (`image`, `segmentation`) pairs saved above. \n",
    "\n",
    "TUNABLE PARAMETER: \n",
    "- `segmenter_update_epochs`: how many epochs to update the segmenter with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47506874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "if unet:\n",
    "    segmenter = unet_model.unet_model()\n",
    "    segmenter_train_dir = new_saved_oracle_filepaths\n",
    "else:\n",
    "    segmenter = nnunet_model.nnunet_model()\n",
    "    segmenter_train_dir = os.path.join(os.environ['nnUNet_preprocessed'], f'Task{task_id}_{run_id}')\n",
    "segmenter.load_model(segmenter_train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368bc3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the segmenter using the correct image, segmentation pairs\n",
    "segmenter_update_epochs = 5 ## TUNABLE PARAMETEr\n",
    "segmenter.update_model(num_epochs = segmenter_update_epochs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0cb5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# potentially save model this iteration if we want. # to be used later \n",
    "if unet:\n",
    "    model_save_path = os.path.join(run_dir, \"unetmodel.pth\")\n",
    "else:\n",
    "    model_save_path = os.path.join(run_dir, 'all', \"Iter\" + str(iter_num)+\".model\")\n",
    "segmenter.save_model(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979efa1",
   "metadata": {},
   "source": [
    "### Visualize Segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b5cd4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if unet: \n",
    "    base_dir = \"/usr/xtmp/vs196/mammoproj/Data/final_dataset/train/*\"\n",
    "else:\n",
    "    base_dir = '/usr/xtmp/jly16/mammoproj/data/nnUNet_raw_data_base/nnUNet_raw_data/Task504_duke-mammo/imagesTr'\n",
    "filepaths = [str(f) for f in np.random.choice(glob.glob(os.path.join(base_dir, '*')), 5)]\n",
    "\n",
    "print(filepaths)\n",
    "segmenter.show_segmentations(filepaths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0382ab",
   "metadata": {},
   "source": [
    "### Generate Predictions and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation 1: generate new segmentations of TRAINING images and save them. (This is for the next stage of active learning)\n",
    "\n",
    "# Dir for segmentations marked correct by the oracle. We do not want to overwrite the old segmentation, so save them here as an archive\n",
    "correct_save_dir = os.path.join(run_dir, \"Segmentations_C\" )\n",
    "# Dir for completely new set of segmentations created by the updated segmenter\n",
    "save_dir = os.path.join(run_dir,\"Segmentations\")\n",
    "\n",
    "if unet: \n",
    "    segmentation_folder = discriminator_training_dir\n",
    "else:\n",
    "    segmentation_folder = '/usr/xtmp/jly16/mammoproj/data/nnUNet_raw_data_base/nnUNet_raw_data/Task504_duke-mammo/imagesTr'\n",
    "\n",
    "segmenter.predict(segmentation_folder, save_dir, correct_save_dir = correct_save_dir, saved_oracle_filepaths = saved_oracle_filepaths)   \n",
    "# Push save_dir as the oracle image dir for the next iteration. That's where we populate with unbinarized segmentations from recently trained UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831cff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation 2: generate segmentations of VALIDATION and see how accurate our new segmenter is\n",
    "if unet:\n",
    "    valid_input_dir =  f\"/usr/xtmp/vs196/mammoproj/Data/manualfa/manual_validation/\"\n",
    "    valid_output_dir = None\n",
    "else:\n",
    "    valid_input_dir = os.path.join(\n",
    "        os.environ['nnUNet_raw_data_base'], 'nnUNet_raw_data', f\"Task504_duke-mammo\", 'imagesTs')\n",
    "    valid_output_dir = os.path.join(run_dir, \"ValSegmentations\")\n",
    "validation_metric = segmenter.validate(valid_input_dir, valid_output_dir)\n",
    "print(f\"Metric of new segmenter after active learning is: {validation_metric}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18937330",
   "metadata": {},
   "source": [
    "### Plotting Active Learning Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c92b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Prints out metrics for all the patient scores from each update.\n",
    "# for i in all_patient_scores:\n",
    "#     print(oracle.calculate_dispersion_metric(i,oracle_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd22e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot the disperson metric\n",
    "# j = []\n",
    "# for i in all_patient_scores:\n",
    "#     j.append(oracle.calculate_dispersion_metric(i,oracle_results))\n",
    "    \n",
    "# plt.plot(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238b0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

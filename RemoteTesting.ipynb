{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "native-uncle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manually leveling\n"
     ]
    }
   ],
   "source": [
    "print('manually leveling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77abad",
   "metadata": {},
   "source": [
    "## Import Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b601e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from time import time\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib.pyplot import imsave, imread\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ad1510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from floodfill import *\n",
    "from dataloader import *\n",
    "from model import *\n",
    "from oracle import *\n",
    "from unet import *\n",
    "import ternausnet.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bf5c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vivek.model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81907ee",
   "metadata": {},
   "source": [
    "## Testing Jupyter Notebook Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc3727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is your name: alina\n",
      "Your name is: alina.\n"
     ]
    }
   ],
   "source": [
    "#Testing live input from user\n",
    "users_name = input(\"what is your name: \")\n",
    "print(f\"Your name is: {users_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "acfdec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 256, 256)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tests loading an image from a directory\n",
    "im_dir = \"/usr/xtmp/mammo/image_datasets/data_split_july2021/square_ROI_by_shape_segmentations_unbin/train/\"\n",
    "im_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_03_10_a/Iter1/UNetSegmentations_ff/\"\n",
    "#im_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/UNetSegmentations/Iter0_ff/Oval/\"\n",
    "#im_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_11_29_a/Iter2/UNetSegmentations_C/Oval/\"\n",
    "#im_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_11_29_a/Iter2/UNetSegmentations_C/Round/\"\n",
    "# im_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_11_24_b/Iter1/UNetSegmentations_C/Oval/\"\n",
    "#im_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/UNetSegmentations/Iter0_ff/Round/\"\n",
    "#ims = [\"DP_ACRF_18645_1.npy\"]\n",
    "#im_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_02_10_a/Iter1/OracleThresholdedImages_ff/Irregular/\"\n",
    "ims = [\"Oval/DP_AGYG_113509_1.npy\"]\n",
    "\n",
    "for im in ims:\n",
    "    path = im_dir + im;\n",
    "    arr = np.load(path)\n",
    "    #arr = np.where(arr > 0.2,1,0)\n",
    "    print(arr.shape)\n",
    "    \n",
    "plt.imshow(arr[1],cmap='jet')\n",
    "#plt.show()\n",
    "im_dir = save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c894ee31",
   "metadata": {},
   "source": [
    "## Active Learning: Setup - Run once per run id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb5d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"01_01_b\" #Format: Month_Day_(Run # that day by letter)\n",
    "#run_id = \"02_10_a\"\n",
    "#run_id = \"02_28_a\"\n",
    "#original \n",
    "#01_01_b is where we load from alina's oracle results\n",
    "#02_28_a is where we load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ab0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f60f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = \"/usr/xtmp/mammo/image_datasets/data_split_july2021/square_ROI_by_shape_segmentations_unbin/train/\"\n",
    "#im_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_02_28_a/Iter1/OracleThresholdedImages_ff/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "487ea26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/26 [00:04<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#Gets the dataloader. Passes in directory of ALL images\n",
    "#im_dir = \"/usr/xtmp/mammo/image_datasets/data_split_july2021/square_ROI_by_shape_segmentations/train/\"\n",
    "#GET THE NEW IM_DIR FOR SUBSEQUENT ITERATIONS\n",
    "im_dir = \"/usr/xtmp/mammo/image_datasets/data_split_july2021/square_ROI_by_shape_segmentations_unbin/train/\"\n",
    "dataloader = get_DataLoader(im_dir,32,2)\n",
    "\n",
    "#Tests the dataloader\n",
    "for i in tqdm(dataloader):\n",
    "#     print(max(i[1]))\n",
    "    print(i[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "765929c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing info arrays for active learning. oracle_results maps patientIDs to 0,1 labels\n",
    "oracle_results = {}\n",
    "oracle_results_thresholds = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e48a9b",
   "metadata": {},
   "source": [
    "## Active Learning: Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9568e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Initializes and trains the model. Plots a loss function of the initial training\n",
    "model,loss_tracker,criterion,optimizer = initialize_and_train_model(dataloader, epochs=5) #default batch_size and epochs\n",
    "plt.plot(loss_tracker) #plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b7b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patient_scores = []\n",
    "\n",
    "#right now patient_scores is initial scores for each patient (without active learning training)\n",
    "patient_scores = get_patient_scores(model,dataloader) \n",
    "all_patient_scores.append(patient_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006f471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_oracle_results, new_oracle_results_thresholds = query_oracle(oracle_results,oracle_results_thresholds,\n",
    "                                                                 patient_scores,im_dir,query_method=\"percentile=0.8\",\n",
    "                                                                 query_number=20)\n",
    "oracle_results, oracle_results_thresholds = new_oracle_results, new_oracle_results_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_num+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_scores = get_patient_scores(model,dataloader)\n",
    "all_patient_scores.append(patient_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff0ecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: track model loss somehow along with patient_scores\n",
    "for i in range(1):\n",
    "    model = model_update(model,dataloader,oracle_results,criterion,optimizer,num_epochs=5)\n",
    "\n",
    "    patient_scores = get_patient_scores(model,dataloader)\n",
    "    all_patient_scores.append(patient_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bded4f",
   "metadata": {},
   "source": [
    "## Metrics and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f48fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints out all patient scores.\n",
    "for i in all_patient_scores:\n",
    "    print(calculate_dispersion_metric(i,oracle_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc8711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the disperson metric\n",
    "j = []\n",
    "for i in all_patient_scores:\n",
    "    j.append(calculate_dispersion_metric(i,oracle_results))\n",
    "    \n",
    "plt.plot(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52692eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of patient scores: \" + str(len(patient_scores)))\n",
    "print(\"Length of oracle results: \" + str(len(oracle_results)))\n",
    "\n",
    "scores = []\n",
    "for key in patient_scores.keys():\n",
    "    scores.append(patient_scores[key])\n",
    "plt.plot(scores)\n",
    "\n",
    "ones = 0\n",
    "for i in oracle_results.keys():\n",
    "    if oracle_results[i]==1:\n",
    "        ones+=1\n",
    "print(\"Number of ones in oracle results: \", ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba948cf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8917f",
   "metadata": {},
   "source": [
    "Jump back to oracle query if you want to query more. Move on to retrain segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cfb1f5",
   "metadata": {},
   "source": [
    "## Saving or Loading Oracle Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70b7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    #SAVE ORACLE\n",
    "\n",
    "    #make filepath\n",
    "    if users_name == 'alina':\n",
    "        save_dir = \"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/CorrectSegmentations/\"\n",
    "    elif users_name == 'vaibhav':\n",
    "        save_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/CorrectSegmentations/\"\n",
    "\n",
    "    saved_oracle_filepaths = save_oracle_results(oracle_results,oracle_results_thresholds,im_dir,save_dir)\n",
    "    fpath = save_dir + \"saved_data_struct/\"\n",
    "    if not os.path.exists(fpath):\n",
    "        os.makedirs(fpath)\n",
    "    saved_oracle_filepaths_filepath = save_dir + \"saved_data_struct/Oracle_Filepaths.pickle\"\n",
    "    pickle.dump(saved_oracle_filepaths,open(saved_oracle_filepaths_filepath,\"wb\"))\n",
    "    pickle.dump(oracle_results,open(save_dir + \"saved_data_struct/Oracle_Results.pickle\",\"wb\"))\n",
    "    pickle.dump(oracle_results_thresholds,open(save_dir + \"saved_data_struct/Oracle_Results_Thresholds.pickle\",\"wb\"))\n",
    "    #TODO: Move border/weight creation to this method and out of convert_directory_to_floodfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34c9d8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_oracle_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fce7e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: #done running if False\n",
    "    #LOAD oracle_results and save_oracle_filepaths\n",
    "    if users_name == 'alina':\n",
    "        save_dir = \"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/CorrectSegmentations/\"\n",
    "    elif users_name == 'vaibhav':\n",
    "        save_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/CorrectSegmentations/\"\n",
    "    saved_oracle_filepaths_filepath = save_dir + \"saved_data_struct/Oracle_Filepaths.pickle\"\n",
    "    #Reload from previous iteration\n",
    "    oracle_results = pickle.load(open(save_dir + \"saved_data_struct/Oracle_Results.pickle\",\"rb\"))\n",
    "    oracle_results_thresholds = pickle.load(open(save_dir + \"saved_data_struct/Oracle_Results_Thresholds.pickle\",\"rb\"))\n",
    "    saved_oracle_filepaths = pickle.load(open(saved_oracle_filepaths_filepath,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2eb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # RECOVER an accidentally delted oracle (recovers correct segmentations only)\n",
    "    oracle_results = {}\n",
    "    if users_name == 'alina':\n",
    "        recover_from_dir = \"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/CorrectSegmentations/\"\n",
    "    for root, dirs, files in os.walk(recover_from_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".npy\"):\n",
    "                filepath = os.path.join(root, file)\n",
    "                print(filepath.split('/')[])\n",
    "                break\n",
    "                oracle_results[file[:-4]] = 1\n",
    "\n",
    "    # pickle.dump(oracle_results,open(recover_from_dir + \"saved_data_struct/Oracle_Results.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa7a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all 0's from oracle_results.\n",
    "oracle_results = remove_bad_oracle_results(oracle_results)\n",
    "#NOTE: Don't FULLY reset oracle_results EVER during a run, only do above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8905a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Irregular/DP_ADIC_26894_1': 1, 'Round/DP_ADVC_33157_1': 1, 'Oval/DP_AEUO_49672_1': 1, 'Oval/DP_AAPK_629_2': 0, 'Oval/DP_ACHA_14536_1': 0, 'Oval/DP_AGYG_113509_1': 0, 'Oval/DP_ADXM_34322_1': 0, 'Round/DP_ADRF_31279_1': 1, 'Irregular/DP_AGUO_110369_1': 0, 'Round/DP_ADNG_29364_1': 1, 'Oval/DP_ACRG_18653_1': 1, 'Irregular/DP_AJXU_86374_1': 0, 'Oval/DP_AAKK_4745_1': 1, 'Irregular/DP_ACBW_12762_1': 1, 'Oval/DP_AAOS_6117_1': 1, 'Irregular/DP_AGRK_107541_1': 0, 'Oval/DP_AEQW_47117_1': 1, 'Round/DP_ACCG_12873_1': 1, 'Oval/DP_AEVQ_50807_1': 0, 'Oval/DP_ACXI_21351_1': 1, 'Round/DP_AIAI_136260_1': 0, 'Irregular/DP_AGCR_94838_1': 0, 'Round/DP_ADMN_28947_1': 0, 'Irregular/DP_AHBR_116103_1': 0, 'Irregular/DP_AIEP_140492_1': 0, 'Oval/DP_AEUS_49967_1': 1, 'Oval/DP_AGFC_97468_1': 0, 'Irregular/DP_ABOZ_176218_3': 1, 'Irregular/DP_AEGA_38993_1': 1, 'Irregular/DP_AIUT_156012_1': 1, 'Oval/DP_AEKJ_41409_1': 1, 'Irregular/DP_ADUT_32983_1': 0, 'Oval/DP_AFLJ_65777_1': 0, 'Oval/DP_AIHC_143250_1': 0, 'Oval/DP_AGYP_113678_1': 0, 'Irregular/DP_ALAR_23841_2': 1, 'Irregular/DP_AAWK_9395_1': 1, 'Round/DP_AIPE_150610_1': 0, 'Round/DP_ALRA_40033_1': 1, 'Irregular/DP_AKVX_18673_1': 1, 'Oval/DP_ABTP_179484_1': 1, 'Oval/DP_AETA_48606_1': 1, 'Round/DP_ABIF_169242_1': 1, 'Oval/DP_ABTG_179151_1': 1, 'Oval/DP_ADQQ_30942_1': 1, 'Oval/DP_AGGY_98823_1': 1, 'Irregular/DP_ADIC_26895_3': 1, 'Oval/DP_AFJP_63921_1': 1, 'Oval/DP_ADLP_28570_1': 1, 'Oval/DP_ADWF_33711_1': 1, 'Oval/DP_AGXV_113192_1': 1, 'Irregular/DP_AJRA_80525_1': 1, 'Oval/DP_ACDW_13427_1': 1, 'Irregular/DP_AKSX_15667_1': 1, 'Irregular/DP_AGUO_110368_1': 1, 'Oval/DP_AEPF_45559_1': 1, 'Oval/DP_ACRF_18645_1': 1, 'Irregular/DP_AFJT_64147_1': 1, 'Oval/DP_ACRF_18647_1': 1, 'Round/DP_AGGY_98820_1': 1, 'Oval/DP_ADFA_25539_1': 0, 'Irregular/DP_AJQW_80310_1': 1, 'Irregular/DP_AJYD_86654_1': 1, 'Irregular/DP_AIUS_155995_1': 0, 'Irregular/DP_AEPB_45464_1': 1, 'Round/DP_ADWF_33714_1': 1, 'Irregular/DP_AKVP_18401_1': 1, 'Irregular/DP_AAFX_3048_1': 1, 'Irregular/DP_ADGC_26118_1': 1, 'Irregular/DP_AIUL_155476_1': 1, 'Round/DP_ACMA_16416_1': 0, 'Round/DP_ADLQ_28577_1': 1, 'Irregular/DP_AHXN_133910_1': 1, 'Irregular/DP_AFNO_67725_1': 1, 'Irregular/DP_ADNG_29366_1': 1, 'Oval/DP_AGEM_97001_1': 1, 'Oval/DP_AJKR_192930_1': 1, 'Oval/DP_AAZO_161745_2': 0, 'Round/DP_AAGX_3496_1': 1, 'Oval/DP_AHOD_126111_1': 0, 'Irregular/DP_AIUL_155471_1': 1, 'Oval/DP_AHTV_130725_1': 1, 'Oval/DP_ALBZ_24811_1': 1, 'Oval/DP_AEWN_51567_1': 1, 'Oval/DP_AKGK_4563_1': 1, 'Oval/DP_AEPF_45557_1': 1, 'Irregular/DP_AACA_167_1': 1, 'Irregular/DP_ADCL_24198_1': 1, 'Irregular/DP_ACHS_14816_1': 1, 'Irregular/DP_AAOR_6110_1': 1, 'Irregular/DP_AICA_137800_1': 1, 'Irregular/DP_ADWF_33713_1': 1, 'Round/DP_AIAX_136595_1': 1, 'Oval/DP_AFJP_63922_1': 1, 'Irregular/DP_ACIY_15278_1': 1, 'Oval/DP_AJHY_189729_1': 1, 'Irregular/DP_AHYT_134899_1': 1, 'Irregular/DP_ACYE_21697_1': 1, 'Irregular/DP_AKSX_15668_1': 1, 'Oval/DP_ALBO_24409_1': 1, 'Irregular/DP_AAYT_160711_1': 1, 'Oval/DP_AHNY_126002_1': 0, 'Round/DP_AGSO_108513_2': 1, 'Oval/DP_AHCR_117065_1': 1, 'Irregular/DP_AAWQ_9468_1': 1, 'Oval/DP_ALHN_30120_1': 1, 'Oval/DP_ABTG_179154_1': 1, 'Oval/DP_ABOX_101145_1': 1, 'Oval/DP_AAOS_6116_1': 1, 'Oval/DP_AAHN_3820_1': 1, 'Oval/DP_AGOD_104981_1': 1, 'Round/DP_ACYY_22756_1': 0, 'Oval/DP_ACKV_16086_2': 0, 'Oval/DP_AFZU_91703_1': 1, 'Oval/DP_AEAY_36284_1': 1, 'Round/DP_AAEL_2453_1': 1, 'Oval/DP_AHHL_121166_1': 1, 'Round/DP_ADGC_26115_1': 0, 'Irregular/DP_ALDY_26335_2': 1, 'Oval/DP_ABJK_171169_1': 0, 'Oval/DP_AGXT_113034_1': 0, 'Round/DP_AIJD_144994_1': 0, 'Round/DP_AIJD_144991_1': 0, 'Oval/DP_AEFG_38522_1': 1, 'Oval/DP_ADDP_24723_1': 0, 'Oval/DP_AGFD_97491_1': 0, 'Oval/DP_ADIC_26894_4': 1, 'Irregular/DP_AIAX_136594_1': 1, 'Oval/DP_AANM_5810_1': 1, 'Irregular/DP_AIMT_148096_1': 1, 'Oval/DP_AFWX_78519_1': 1, 'Oval/DP_AKXF_20410_1': 1, 'Irregular/DP_ADLQ_28578_1': 1, 'Irregular/DP_AJNO_195728_1': 1, 'Oval/DP_AIWM_158482_1': 0, 'Oval/DP_AFEE_58552_1': 1, 'Irregular/DP_AHIT_122303_1': 1, 'Oval/DP_ABTP_179481_1': 1, 'Irregular/DP_ALDY_26334_2': 1, 'Oval/DP_AAQU_6780_1': 1, 'Oval/DP_ABMC_173639_1': 1, 'Irregular/DP_AKOO_11845_1': 1, 'Irregular/DP_AFNO_67722_1': 1, 'Round/DP_ACCG_12875_1': 1, 'Oval/DP_AAGG_3178_1': 1, 'Oval/DP_AGOY_105492_1': 1, 'Round/DP_AIDV_139677_1': 1, 'Round/DP_AGUF_110009_1': 1, 'Round/DP_AHPO_127420_1': 1, 'Oval/DP_AGJJ_100840_1': 1, 'Irregular/DP_AGXV_113195_1': 0, 'Round/DP_AFSR_72215_1': 1, 'Oval/DP_AHZI_135591_1': 1, 'Oval/DP_AIWM_158483_1': 1, 'Irregular/DP_ADCL_24202_1': 0, 'Irregular/DP_AFJT_64146_1': 1, 'Oval/DP_ABJX_171694_1': 0, 'Round/DP_AADU_2248_1': 1, 'Irregular/DP_AACA_163_1': 1, 'Oval/DP_AGYP_113684_1': 1, 'Oval/DP_ABCT_164329_2': 0, 'Irregular/DP_ALRI_40246_1': 1, 'Irregular/DP_ALDK_25783_1': 1, 'Oval/DP_AHPW_127511_1': 1, 'Oval/DP_AGFV_98144_1': 1, 'Oval/DP_ABTP_179482_1': 1, 'Oval/DP_ALHB_29690_1': 1, 'Irregular/DP_AEAF_35762_1': 1, 'Oval/DP_AAMJ_5545_1': 1, 'Oval/DP_AJKG_192265_1': 0, 'Round/DP_AFZU_91700_1': 1, 'Oval/DP_AERR_47680_1': 1, 'Oval/DP_AAQU_6780_2': 1, 'Round/DP_AFXA_78611_1': 1, 'Irregular/DP_ACTC_19453_1': 1, 'Irregular/DP_ALDB_25587_1': 1, 'Oval/DP_AEWN_51571_1': 1, 'Oval/DP_AKUT_17603_1': 0, 'Oval/DP_AIZC_181035_1': 0, 'Oval/DP_AAYB_53433_1': 0, 'Round/DP_AEBE_36368_1': 0, 'Irregular/DP_AITS_80457_1': 0, 'Irregular/DP_AAXL_9792_1': 0, 'Oval/DP_AGOT_105361_1': 1, 'Oval/DP_ADFA_25538_1': 0, 'Oval/DP_AIPU_151147_1': 1, 'Irregular/DP_ACJY_15690_1': 1, 'Irregular/DP_AIVZ_157928_1': 1, 'Irregular/DP_AKAI_88577_1': 1, 'Irregular/DP_AGRK_107543_1': 0, 'Oval/DP_ADIC_26895_1': 0, 'Oval/DP_AAIG_4056_1': 1, 'Irregular/DP_AKAI_88574_1': 1, 'Oval/DP_ABZA_11901_1': 0, 'Round/DP_AAUO_8709_1': 1, 'Oval/DP_AAZA_161129_1': 1, 'Round/DP_ACFV_14111_1': 0, 'Irregular/DP_ADYL_99130_1': 1, 'Irregular/DP_ACXI_21348_1': 1, 'Oval/DP_AGXT_113033_1': 1, 'Irregular/DP_AADN_2148_1': 1, 'Irregular/DP_AJQW_80315_1': 0, 'Oval/DP_ABZA_11902_1': 0, 'Irregular/DP_AFPO_69422_1': 1, 'Oval/DP_AGMB_103457_1': 0, 'Round/DP_ADLQ_28577_2': 1, 'Oval/DP_AHZI_135596_1': 1, 'Oval/DP_AEHC_39471_1': 0, 'Irregular/DP_AGEQ_97110_1': 0, 'Oval/DP_AGFV_98143_1': 0, 'Oval/DP_AJHY_189730_1': 1, 'Oval/DP_ABRY_178342_1': 0, 'Round/DP_AAOG_5951_1': 0, 'Oval/DP_ADGQ_26328_1': 1, 'Irregular/DP_ADLQ_28579_1': 1, 'Oval/DP_AFGV_61209_1': 0, 'Oval/DP_AANM_5811_1': 1, 'Oval/DP_ALUT_44531_1': 0, 'Oval/DP_ACHS_14815_2': 1, 'Oval/DP_ACXW_21606_1': 1, 'Oval/DP_AGKC_101351_1': 1, 'Oval/DP_AGZJ_114093_2': 1, 'Round/DP_AAGX_3497_1': 1, 'Irregular/DP_AJUE_83297_2': 1, 'Round/DP_ACQD_18190_1': 1, 'Oval/DP_AAMJ_5544_1': 1, 'Oval/DP_AAEU_173631_1': 1, 'Irregular/DP_AITJ_154346_1': 1, 'Irregular/DP_ALAR_23841_1': 1, 'Oval/DP_AIMT_148094_1': 1, 'Irregular/DP_ADLR_28610_1': 1, 'Oval/DP_ADLY_28737_1': 1, 'Irregular/DP_ALAR_23843_1': 1, 'Irregular/DP_ACJY_15684_1': 1, 'Irregular/DP_ABOZ_176218_2': 1, 'Irregular/DP_ADIC_26894_2': 1, 'Oval/DP_AHPW_127514_1': 1, 'Irregular/DP_AHYC_134388_1': 1, 'Irregular/DP_AKXN_20679_1': 1, 'Oval/DP_AGOY_105489_1': 1, 'Irregular/DP_AHIQ_122202_1': 0, 'Oval/DP_AGAU_93007_1': 1, 'Irregular/DP_AJUE_83297_1': 1, 'Oval/DP_AAOT_6127_1': 1, 'Round/DP_AKKN_7731_1': 1, 'Oval/DP_ACZY_23113_1': 1, 'Round/DP_AKDY_2517_1': 1, 'Irregular/DP_AKAY_89028_1': 1, 'Irregular/DP_ABYY_11777_1': 1, 'Oval/DP_AERR_47679_1': 1, 'Round/DP_AFEP_59122_1': 1, 'Round/DP_AFEP_59124_1': 1, 'Irregular/DP_AKOO_11843_1': 1, 'Irregular/DP_ACJY_15689_1': 1, 'Irregular/DP_AJTT_82942_1': 1, 'Irregular/DP_AISN_153459_1': 1, 'Irregular/DP_AIAF_136233_1': 1, 'Oval/DP_ACWJ_20831_1': 1, 'Irregular/DP_AIUL_155475_1': 1, 'Oval/DP_ACNW_17344_1': 1, 'Irregular/DP_AHYT_134896_1': 0, 'Irregular/DP_AAWQ_9462_1': 0, 'Oval/DP_ADXC_34098_1': 1, 'Oval/DP_ACHA_14534_1': 1, 'Irregular/DP_ALQX_39968_1': 0, 'Irregular/DP_AADN_2149_1': 1, 'Round/DP_AFEM_58986_1': 1, 'Oval/DP_ABHR_168796_1': 1, 'Oval/DP_AAQU_6779_1': 1, 'Irregular/DP_AEUZ_50187_1': 1, 'Irregular/DP_ACPD_17747_1': 1, 'Irregular/DP_AAWK_9394_1': 1, 'Oval/DP_AEHI_39554_1': 0, 'Round/DP_AGLB_102567_1': 1, 'Oval/DP_ALDY_26335_1': 1, 'Oval/DP_ACLE_16146_1': 1, 'Oval/DP_AHOP_126451_1': 1, 'Round/DP_ALFQ_28104_1': 1, 'Irregular/DP_ACPD_17746_1': 1, 'Irregular/DP_ADPO_30489_1': 0, 'Oval/DP_AKDY_2515_1': 1, 'Oval/DP_ACYT_22717_1': 1, 'Oval/DP_AFRZ_71799_1': 1, 'Oval/DP_ADRK_31336_1': 0, 'Oval/DP_ADPO_30492_1': 1, 'Oval/DP_AFJD_63452_1': 0, 'Round/DP_AHXS_134034_1': 1, 'Irregular/DP_AJOU_197106_1': 0, 'Irregular/DP_ADQD_27965_1': 1, 'Oval/DP_AEIF_40165_1': 1, 'Oval/DP_AGYV_113800_1': 1, 'Oval/DP_AGKC_101349_1': 1, 'Irregular/DP_AIBS_137447_1': 1, 'Irregular/DP_ADLQ_28578_3': 0, 'Oval/DP_AEBF_36373_1': 1, 'Oval/DP_AHYB_134331_1': 1, 'Irregular/DP_AJUZ_84243_1': 1, 'Irregular/DP_AEUG_49389_1': 1, 'Oval/DP_ADLQ_28579_2': 1, 'Oval/DP_AHGL_120383_1': 1, 'Irregular/DP_AIBS_137446_1': 1, 'Oval/DP_AKSE_14976_1': 1, 'Oval/DP_ACHI_14654_1': 1, 'Oval/DP_ACMF_16508_1': 0, 'Oval/DP_AEKJ_41411_1': 1, 'Oval/DP_AJTT_82939_1': 1, 'Oval/DP_ADLQ_28577_3': 1, 'Oval/DP_AETA_48608_1': 1, 'Oval/DP_AJMO_194909_1': 0, 'Round/DP_AHPO_127419_1': 0, 'Irregular/DP_AIHI_143343_1': 0, 'Oval/DP_AHGB_120103_1': 1, 'Irregular/DP_AKPG_12724_1': 1}\n"
     ]
    }
   ],
   "source": [
    "print(oracle_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee83d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_01_01_b/Iter1/CorrectSegmentations/\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "#Convert oracle_results to oracle filepaths\n",
    "all_oracle_filepaths = []\n",
    "    \n",
    "filestem = '/'.join(saved_oracle_filepaths[0].split(\"/\")[:-2]) +\"/\"\n",
    "print(filestem)\n",
    "\n",
    "for key in oracle_results.keys():\n",
    "    all_oracle_filepaths.append(filestem + key + \".npy\")\n",
    "\n",
    "print(len(oracle_all_filepaths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d52ed2",
   "metadata": {},
   "source": [
    "## Retrain UNet and Save New Segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bf75808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retoggle run id if we want to save today's set instead of loading in an old set.\n",
    "if True:\n",
    "    run_id = \"03_10_a\" \n",
    "    \n",
    "#Retoggle user to Vaibhav if I want to save \n",
    "if True:\n",
    "    users_name = \"vaibhav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3807b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [00:58<00:00, 13.98it/s]\n",
      "100%|██████████| 824/824 [05:32<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in /usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_03_10_a/Iter1/OracleThresholdedImages_ff/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Threshold masks based on oracle and save if needed.\n",
    "#If already done, then skip\n",
    "threshold_and_save_flag = True\n",
    "if threshold_and_save_flag:\n",
    "    #Save thresholded\n",
    "    if users_name == 'alina':\n",
    "        save_dir = \"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/OracleThresholdedImages/\"\n",
    "    elif users_name == 'vaibhav':\n",
    "        save_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/OracleThresholdedImages/\"\n",
    "    else:\n",
    "        print(\"wrong username\")\n",
    "        \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    else:\n",
    "        user_input = input(\"Do you want to overwrite this directory? Type y or yes to continue\")\n",
    "        if not (user_input==\"y\" or user_input==\"yes\"):\n",
    "            assert(False)\n",
    "    #find all filepaths in im_dir\n",
    "    all_filepaths = []\n",
    "    for root, dirs, files in os.walk(im_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".npy\"):\n",
    "                all_filepaths.append(os.path.join(root, file))\n",
    "    threshold_and_save_images(all_filepaths, oracle_results_thresholds, save_dir)\n",
    "    save_dir = convert_directory_to_floodfill(save_dir,iter0=False)\n",
    "    print(f\"Saved in {save_dir}\")\n",
    "    im_dir = save_dir #im_dir is now replaced with the new directory\n",
    "    #save_dir is defunct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82bb3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_dataloader(train_images_filepaths,batch_size,num_workers):\n",
    "    transforms_arr = [transforms.ToTensor(),transforms.Resize((256,256))]\n",
    "    transform = transforms.Compose(transforms_arr)\n",
    "    trainset = InhouseGetData(train_images_filepaths,transform,data_aug=True,has_weights=True)\n",
    "    trainloader = DataLoader(trainset,batch_size=batch_size,num_workers=num_workers)\n",
    "    return trainloader\n",
    "\n",
    "class InhouseGetData(Dataset):\n",
    "    def __init__(self,image_filepaths,image_transform,data_aug=True,has_weights=True):\n",
    "        super().__init__()\n",
    "        self.image_filepaths = image_filepaths\n",
    "        self.image_transform = image_transform\n",
    "        self.data_aug = data_aug\n",
    "        self.has_weights = has_weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filepaths)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        filepath = self.image_filepaths[idx]\n",
    "        #print(\"Filepath: \" + filepath)\n",
    "        arr_and_mask = np.load(filepath)\n",
    "        copy_arr_mask = arr_and_mask.copy()\n",
    "        if self.data_aug:\n",
    "            copy_arr_mask = random_flip(copy_arr_mask, 0, True)\n",
    "            copy_arr_mask = random_flip(copy_arr_mask, 1, True)\n",
    "            copy_arr_mask = random_rotate_90(copy_arr_mask, True)\n",
    "            copy_arr_mask = random_rotate_90(copy_arr_mask, True)\n",
    "            copy_arr_mask = random_rotate_90(copy_arr_mask, True)\n",
    "        arr = copy_arr_mask[0,:,:].copy()\n",
    "        mask = copy_arr_mask[1,:,:].copy()\n",
    "        if self.has_weights:\n",
    "            weights = copy_arr_mask[2,:,:].copy()\n",
    "        arr = exposure.equalize_hist(arr) #histogram equalization, remove if u want\n",
    "        #arr = np.stack([arr,arr,arr])\n",
    "        #mask = np.stack([mask,mask,mask])\n",
    "        #no need to preprocess\n",
    "        #print(\"INSIDE\")\n",
    "        #print(arr.shape)\n",
    "        \n",
    "        image = self.image_transform(arr)\n",
    "        #image = our_transform(image)\n",
    "        #print(image.shape)\n",
    "        #print(\"OUTSIDE\")\n",
    "        mask_label = self.image_transform(mask)\n",
    "        #mask_label = our_transform(mask_label)\n",
    "        if self.has_weights:\n",
    "            weights_label = self.image_transform(weights)\n",
    "            #weights_label = our_transform(weights_label)\n",
    "        #a transform\n",
    "        # print(arr.shape)\n",
    "        # print(mask.shape)\n",
    "        \n",
    "        # transformed = self.a_transform(image=arr, mask=mask)\n",
    "        # a_image = transformed[\"image\"]\n",
    "        # a_mask = transformed[\"mask\"]\n",
    "        if self.has_weights:\n",
    "            return image,mask_label,weights_label\n",
    "        return image,mask_label\n",
    "\n",
    "\n",
    "def get_binary_mask(mask,threshold):\n",
    "    return np.where(mask > threshold, 1, 0)\n",
    "    \n",
    "class InhouseGetData_v2(InhouseGetData):\n",
    "    def __init__(self,image_filepaths,oracle_results_thresholds,image_transform,data_aug=True,has_weights=True):\n",
    "        InhouseGetData.__init__(self,image_filepaths,image_transform,data_aug,has_weights)\n",
    "        self.oracle_results_thresholds = oracle_results_thresholds\n",
    "    def __getitem__(self,idx):\n",
    "        filepath = self.image_filepaths[idx]\n",
    "        #print(\"Filepath: \" + filepath)\n",
    "        arr_and_mask = np.load(filepath)\n",
    "        copy_arr_mask = arr_and_mask.copy()\n",
    "        if self.data_aug:\n",
    "            copy_arr_mask = random_flip(copy_arr_mask, 0, True)\n",
    "            copy_arr_mask = random_flip(copy_arr_mask, 1, True)\n",
    "            copy_arr_mask = random_rotate_90(copy_arr_mask, True)\n",
    "            copy_arr_mask = random_rotate_90(copy_arr_mask, True)\n",
    "            copy_arr_mask = random_rotate_90(copy_arr_mask, True)\n",
    "        arr = copy_arr_mask[0,:,:].copy()\n",
    "        mask = copy_arr_mask[1,:,:].copy()\n",
    "        #apply threshold to mask\n",
    "        threshold = self.oracle_results_thresholds[(\"/\".join(filepath.split(\"/\")[-2:]))[:-4]]\n",
    "        mask = get_binary_mask(mask,threshold)\n",
    "        if self.has_weights:\n",
    "            weights = copy_arr_mask[2,:,:].copy()\n",
    "        arr = exposure.equalize_hist(arr) #histogram equalization, remove if u want\n",
    "        \n",
    "        image = self.image_transform(arr)\n",
    "        mask_label = self.image_transform(mask)\n",
    "        if self.has_weights:\n",
    "            weights_label = self.image_transform(weights)\n",
    "        if self.has_weights:\n",
    "            return image,mask_label,weights_label\n",
    "        return image,mask_label\n",
    "        \n",
    "    \n",
    "def unet_dataloader_v2(saved_oracle_filepaths,oracle_results_thresholds,batch_size=8,num_workers=2):\n",
    "    transforms_arr = [transforms.ToTensor(),transforms.Resize((256,256))]\n",
    "    transform = transforms.Compose(transforms_arr)\n",
    "    trainset = InhouseGetData_v2(saved_oracle_filepaths,oracle_results_thresholds,transform,data_aug=True,has_weights=True)\n",
    "    trainloader = DataLoader(trainset,batch_size=batch_size,num_workers=num_workers)\n",
    "    return trainloader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a7e9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_path = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_02_28_a/Iter1/unetmodel.pth\"\n",
    "custom_load = True\n",
    "if custom_load:\n",
    "    model_path = custom_model_path\n",
    "    unet_model = torch.load(model_path)\n",
    "    \n",
    "else:\n",
    "    #Load in/Initialize a UNet model for retraining\n",
    "\n",
    "    from_scratch = False\n",
    "    #Define the initial UNet model (iter0)\n",
    "    if iter_num==1:\n",
    "        model_path = \"/usr/xtmp/vs196/mammoproj/SavedModels/HyperparameterUNet_nobuffer/unet_5_0.5/Model/unetmodel_FINAL.pth\"\n",
    "    else:\n",
    "        model_path = model_save_path\n",
    "\n",
    "    if not from_scratch:\n",
    "        unet_model = torch.load(model_path)\n",
    "    else:\n",
    "        unet_model = getattr(ternausnet.models, \"UNet16\")(num_classes=2,pretrained=True).cuda()\n",
    "\n",
    "total_loss_tracker = []\n",
    "total_metric_tracker = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f70c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_saved_oracle_filepaths(saved_oracle_filepaths, im_dir):\n",
    "    new_filepaths = [(im_dir + \"/\".join(filepath.split(\"/\")[-2:])) for filepath in saved_oracle_filepaths]\n",
    "    return new_filepaths\n",
    "\n",
    "new_saved_oracle_filepaths = make_new_saved_oracle_filepaths(saved_oracle_filepaths, im_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcf181ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_03_10_a/Iter1/OracleThresholdedImages_ff/\n",
      "03_10_a\n"
     ]
    }
   ],
   "source": [
    "# print(saved_oracle_filepaths[0])\n",
    "# print(new_saved_oracle_filepaths[0])\n",
    "print(im_dir)\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55fa21ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [04:50<00:00,  1.87s/it]\n",
      "100%|██████████| 155/155 [01:26<00:00,  1.79it/s]\n",
      "100%|██████████| 155/155 [01:28<00:00,  1.75it/s]\n",
      "100%|██████████| 155/155 [01:28<00:00,  1.76it/s]\n",
      "100%|██████████| 155/155 [01:28<00:00,  1.75it/s]\n",
      "100%|██████████| 155/155 [01:28<00:00,  1.76it/s]\n",
      "100%|██████████| 155/155 [01:29<00:00,  1.73it/s]\n",
      "100%|██████████| 155/155 [01:27<00:00,  1.77it/s]\n",
      "100%|██████████| 155/155 [01:28<00:00,  1.76it/s]\n",
      "100%|██████████| 155/155 [01:27<00:00,  1.77it/s]\n",
      "100%|██████████| 155/155 [01:27<00:00,  1.78it/s]\n",
      "100%|██████████| 155/155 [01:27<00:00,  1.77it/s]\n",
      "100%|██████████| 155/155 [01:29<00:00,  1.73it/s]\n",
      "100%|██████████| 155/155 [01:28<00:00,  1.75it/s]\n",
      "100%|██████████| 155/155 [01:28<00:00,  1.76it/s]\n",
      "100%|██████████| 155/155 [01:28<00:00,  1.76it/s]\n",
      "100%|██████████| 155/155 [01:28<00:00,  1.75it/s]\n",
      "100%|██████████| 155/155 [01:26<00:00,  1.79it/s]\n",
      "100%|██████████| 155/155 [01:28<00:00,  1.76it/s]\n",
      "100%|██████████| 155/155 [01:28<00:00,  1.74it/s]\n"
     ]
    }
   ],
   "source": [
    "#Retrain UNet with training data taken from OracleImages/Iter\n",
    "#new_unet_dataloader = unet_dataloader(saved_oracle_filepaths,8,2)\n",
    "new_unet_dataloader = unet_dataloader(new_saved_oracle_filepaths,8,2)\n",
    "cbis_trainloader,_ = CBIS_DDSM_get_DataLoader(8,2)\n",
    "\n",
    "#unet_model,loss_tracker,metric_tracker = unet_update_model(unet_model,cbis_trainloader,num_epochs=15)\n",
    "unet_model,loss_tracker,metric_tracker = unet_update_model_multi_dataloader(unet_model,new_unet_dataloader,cbis_trainloader,num_epochs=20)\n",
    "total_loss_tracker.extend(loss_tracker)\n",
    "total_metric_tracker.extend(metric_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d75650c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1510a8a603c8>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(total_loss_tracker)\n",
    "plt.plot(total_metric_tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "506f155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [00:33<00:00, 24.69it/s]\n"
     ]
    }
   ],
   "source": [
    "#evaluate new segmentations for ALL images \n",
    "#Save SAVED_ORACLE_FILEPATH NEW segmentations to SEPARATE FOLDER for VIEWING ONLY\n",
    "#Save this iteration saved_oracle_filepaths along with new segmentations for all other patients\n",
    "segmentation_folder = im_dir\n",
    "correct_save_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/UNetSegmentations_C/\"\n",
    "save_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/UNetSegmentations/\"\n",
    "#Method creates new segmentations using updated model. \n",
    "#Saves new segmentations for images labelled correctly by the oracle to correct_save_dir\n",
    "#Saves all segmentations (preserved for images labelled correctly by the oracle, new for all others) to save_dir\n",
    "#Have different subfolders for different iterations of unet update\n",
    "evaluate_model_on_new_segmentations_and_save(unet_model,segmentation_folder,saved_oracle_filepaths,correct_save_dir,save_dir,iter_num)\n",
    "\n",
    "#save the model\n",
    "model_save_path = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/unetmodel.pth\"\n",
    "torch.save(unet_model,model_save_path)\n",
    "\n",
    "#save_dir is what we convert to floodfill two cells down.\n",
    "#TODO: ADD TQDM TO EVALUATE_MODEL...\n",
    "#TODO: Add flexibility for alina saving (add alina paths)\n",
    "#TODO: Update evaluate model to output two channels where the first is the same as now and the second is a continuous version of the mask.\n",
    "#Look at bad oracles and see if those got better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb739f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_02_28_a/Iter1/UNetSegmentations\"\n",
    "iter_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39ca29ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [05:29<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "#Convert initial UNet Segmentations to flood-filled and resave\n",
    "#raw_segmentation_folder = \"/usr/xtmp/mammo/image_datasets/data_split_july2021/square_ROI_by_shape_segmentations/train/\"\n",
    "raw_segmentation_folder = save_dir #remove for rerun\n",
    "im_dir = convert_directory_to_floodfill(raw_segmentation_folder,iter0=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd7cf395",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_11_29_a/Iter1/UNetSegmentations_ff/\"\n",
    "im_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_02_28_a/Iter1/UNetSegmentations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd7931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reloading iter 1 purposes\n",
    "iter_num = 2\n",
    "im_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_11_23_a/Iter1/UNetSegmentations_ff/\"\n",
    "dataloader = get_DataLoader(im_dir,32,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e566dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(iter_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f94a622b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_03_10_a/Iter1/UNetSegmentations_ff/\n"
     ]
    }
   ],
   "source": [
    "print(im_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f4ce2a",
   "metadata": {},
   "source": [
    "# Saving Images for Fides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41d54096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_annotation(filepath,annotations):\n",
    "    ncols, nrows = 3, len(filepath)\n",
    "    fig = plt.figure(constrained_layout=False)\n",
    "    fig.set_size_inches(9, 3*len(filepath)+1)\n",
    "    fig.tight_layout()\n",
    "    spec = gridspec.GridSpec(ncols=ncols, nrows=nrows, figure=fig,hspace=0,wspace=0)\n",
    "    \n",
    "    anno_opts = dict(xy=(0.05, 0.05), xycoords='axes fraction', va='bottom', ha='left',color='cyan',fontweight='extra bold',fontsize='8')\n",
    "\n",
    "    f_axes = []\n",
    "    for row in range(nrows):\n",
    "        f_axes.append([])\n",
    "        for col in range(ncols):\n",
    "            f_axes[-1].append(fig.add_subplot(spec[row, col]))\n",
    "\n",
    "    for ax_num, ax in enumerate(f_axes[0]):\n",
    "            if ax_num == 0:\n",
    "                ax.set_title(\"Image\", fontdict=None, loc='left', color = \"k\")\n",
    "            elif ax_num == 1:\n",
    "                ax.set_title(\"Segmentation\", fontdict=None, loc='left', color = \"k\")\n",
    "            elif ax_num == 2:\n",
    "                ax.set_title(\"Overlay\", fontdict=None, loc='left', color = \"k\")\n",
    "\n",
    "    for row in range(nrows):\n",
    "        image_and_mask = np.load(filepath[row])\n",
    "        f_axes[row][0].imshow(image_and_mask[0],cmap='gray')\n",
    "        f_axes[row][0].set_axis_off()\n",
    "        \n",
    "        f_axes[row][1].imshow(image_and_mask[1],cmap='gray')\n",
    "        f_axes[row][1].set_axis_off()\n",
    "\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255*(1-image_and_mask[1])), cv2.COLORMAP_AUTUMN)\n",
    "        heatmap = np.float32(heatmap) / 255\n",
    "        heatmap = heatmap[...,::-1]\n",
    "\n",
    "        img = 0.6 * np.stack([image_and_mask[0],image_and_mask[0],image_and_mask[0]],axis=-1) + 0.3*heatmap\n",
    "        f_axes[row][2].imshow(img)\n",
    "        f_axes[row][2].set_axis_off()\n",
    "        \n",
    "        f_axes[row][0].annotate(annotations[row],**anno_opts)\n",
    "\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ff67a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tobechecked_save_dir = \"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/ToBeChecked_neworder/\"\n",
    "\n",
    "exclude_data_from_dirs = [\"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_11_30_a/Iter1/CorrectSegmentations/\",\n",
    "                          \"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_12_19_b/Iter1/CorrectSegmentations/\",\n",
    "                          \"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_12_21_b/Iter1/CorrectSegmentations/\",\n",
    "                          \"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_12_21_b/Iter2/CorrectSegmentations/\",\n",
    "                          \"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_01_01_a/Iter1/CorrectSegmentations/\"\n",
    "                         ]\n",
    "\n",
    "exclude_data_from_dirs = [\"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_01_01_b/Iter1/CorrectSegmentations/\",\n",
    "                          \"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_12_21_b/Iter1/CorrectSegmentations/\"\n",
    "                         ]\n",
    "\n",
    "exclude_patientIDs = set()\n",
    "for exclude_data_from_dir in exclude_data_from_dirs:\n",
    "    already_sent_oracle_filepaths = pickle.load(open(exclude_data_from_dir + \"saved_data_struct/\" + \"Oracle_Filepaths.pickle\",'rb'))\n",
    "    print(len(already_sent_oracle_filepaths))\n",
    "    for already_sent_oracle_filepath in already_sent_oracle_filepaths:\n",
    "        pat_ID = already_sent_oracle_filepath.split('/')[-1][:-4]\n",
    "        exclude_patientIDs.add(pat_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(exclude_patientIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e6f4d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collision_cnt = 0\n",
    "for save_filepath in saved_oracle_filepaths:\n",
    "    #plot the 3 part image as in oracle query\n",
    "    annotation = '/'.join((save_filepath.split('/'))[-2:])\n",
    "    pat_ID = save_filepath.split('/')[-1][:-4]\n",
    "    if pat_ID in exclude_patientIDs:\n",
    "        print(f'collision for {pat_ID}')\n",
    "        collision_cnt += 1\n",
    "    else:\n",
    "        display_image_annotation([save_filepath],[annotation])\n",
    "\n",
    "        #put an annotation on that image with the patient ID and the class\n",
    "        #save the image in tobechecked_save_dir\n",
    "        tobechecked_save_subfolder = os.path.join(tobechecked_save_dir ,save_filepath.split('/')[-2]) + \"/\"\n",
    "        if not os.path.exists(tobechecked_save_subfolder):\n",
    "            os.makedirs(tobechecked_save_subfolder)\n",
    "        save_path = os.path.join(tobechecked_save_dir, annotation)[:-4]+\".png\"\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "\n",
    "print(f\"{collision_cnt} collisions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tobechecked_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_comparison(image1,image2):\n",
    "    display_image_annotation([image1,image2],[image1,image2])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c330590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6b04f9d",
   "metadata": {},
   "source": [
    "# Vivek GAN stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717513e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vivek GAN Playground\n",
    "#Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "#from models import G, D, weights_init (Already imported)\n",
    "#from data import get_training_set, get_test_set\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "#Retrain UNet with training data taken from OracleImages/Iter\n",
    "new_unet_dataloader = unet_dataloader(saved_oracle_filepaths,8,2)\n",
    "#cbis_trainloader,_ = CBIS_DDSM_get_DataLoader(8,2)\n",
    "\n",
    "#Setup code\n",
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    return loss.mean()\n",
    "\n",
    "cudnn.benchmark = True\n",
    "training_data_loader = new_unet_dataloader #replace with data loader from above (in UNET)\n",
    "\n",
    "#DEFINE BATCH_SIZE\n",
    "batch_size = 8\n",
    "\n",
    "#Initialize model and initialization values\n",
    "input_nc = 1\n",
    "output_nc = 1\n",
    "ngf = ndf = 32\n",
    "netG = G(input_nc, output_nc, ngf)\n",
    "netG.apply(weights_init)\n",
    "netD = D(input_nc, output_nc, ndf)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "criterion_l1 = nn.L1Loss()\n",
    "criterion_mse = nn.MSELoss()\n",
    "\n",
    "real_A = torch.FloatTensor(batch_size, input_nc, 256, 256)\n",
    "real_B = torch.FloatTensor(batch_size, output_nc, 256, 256)\n",
    "label = torch.FloatTensor(batch_size)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "#Push everything onto CUDA\n",
    "netD = netD.cuda()\n",
    "netG = netG.cuda()\n",
    "criterion = criterion.cuda()\n",
    "criterion_l1 = criterion_l1.cuda()\n",
    "criterion_mse = criterion_mse.cuda()\n",
    "real_A = real_A.cuda()\n",
    "real_B = real_B.cuda()\n",
    "label = label.cuda()\n",
    "\n",
    "real_A = Variable(real_A)\n",
    "real_B = Variable(real_B)\n",
    "label = Variable(label)\n",
    "\n",
    "#Setup ADAM optimizer - REPLACE\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "lamb = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "#Training Code\n",
    "for iteration, batch in enumerate(tqdm(training_data_loader), 1):\n",
    "    ############################\n",
    "    # (1) Update D network: maximize log(D(x,y)) + log(1 - D(x,G(x)))\n",
    "    ###########################\n",
    "    # train with real\n",
    "    netD.volatile = True\n",
    "    netD.zero_grad()\n",
    "    print(batch[0].shape)\n",
    "    with torch.no_grad():\n",
    "        real_a_cpu, real_b_cpu = batch[0], batch[1]\n",
    "        real_A.resize_(real_a_cpu.size()).copy_(real_a_cpu)\n",
    "        real_B.resize_(real_b_cpu.size()).copy_(real_b_cpu)\n",
    "\n",
    "    output = netD(torch.cat((real_A, real_B), 1))\n",
    "    with torch.no_grad():\n",
    "        label.resize_(output.size()).fill_(real_label)\n",
    "    err_d_real = criterion(output, label)\n",
    "    # print (err_d_real)\n",
    "    err_d_real.backward()\n",
    "    d_x_y = output.data.mean()\n",
    "\n",
    "    # train with fake\n",
    "    fake_b = netG(real_A)\n",
    "    output = netD(torch.cat((real_A, fake_b.detach()), 1))\n",
    "    with torch.no_grad():\n",
    "        label.resize_(output.size()).fill_(fake_label)\n",
    "    err_d_fake = criterion(output, label)\n",
    "    # print (err_d_fake)\n",
    "    err_d_fake.backward()\n",
    "    d_x_gx = output.data.mean()\n",
    "\n",
    "    err_d = (err_d_real + err_d_fake) / 2.0\n",
    "    optimizerD.step()\n",
    "\n",
    "    ############################\n",
    "    # (2) Update G network: maximize log(D(x,G(x))) + L1(y,G(x))\n",
    "    ###########################\n",
    "    netG.zero_grad()\n",
    "    netD.volatile = True\n",
    "    output = netD(torch.cat((real_A, fake_b), 1))\n",
    "    label.data.resize_(output.size()).fill_(real_label)\n",
    "    err_g = criterion(output, label) + lamb * dice_loss(fake_b, real_B)\n",
    "    err_g.backward()\n",
    "    d_x_gx_2 = output.data.mean()\n",
    "    optimizerG.step()\n",
    "    \n",
    "    #Print epoch info\n",
    "    print(\"===> Epoch[{}]({}/{}): Loss_D: {:.4f} Loss_G: {:.4f} D(x): {:.4f} D(G(z)): {:.4f}/{:.4f}\".format(\n",
    "            epoch, iteration, len(training_data_loader), err_d.data[0], err_g.data[0], d_x_y, d_x_gx, d_x_gx_2))\n",
    "\n",
    "\n",
    "#Eval Code\n",
    "\n",
    "#Run Code:\n",
    "#modelD, modelG, criterionD, criterionG, metric_trackerGD = vivek.model_update(modelD, modelG, criterionD, criterionG, dataloader,num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to save segmentations at correct thresholds for use in UNEt training on the same stage\n",
    "\n",
    "#Takes in correct oracle results and thresholds and save path\n",
    "#First threshold it to a binary mask\n",
    "\n",
    "def threshold_and_save_images(saved_oracle_filepaths, oracle_results_thresholds, save_dir):\n",
    "    for filepath in tqdm(saved_oracle_filepaths):\n",
    "        threshold = oracle_results_thresholds[(\"/\".join(filepath.split(\"/\")[-2:]))[:-4]]\n",
    "        arr_and_mask = np.load(filepath)\n",
    "        copy_arr_mask = arr_and_mask.copy()\n",
    "\n",
    "        arr = copy_arr_mask[0,:,:].copy()\n",
    "        mask = copy_arr_mask[1,:,:].copy()\n",
    "        #apply threshold to mask\n",
    "        mask = get_binary_mask(mask, threshold)\n",
    "        to_save = np.stack([arr, mask])\n",
    "        \n",
    "        save_save_dir = save_dir + \"/\".join(filepath.split(\"/\")[-2:])\n",
    "        if not os.path.exists(save_dir + filepath.split(\"/\")[-2]):\n",
    "            os.makedirs(save_dir + filepath.split(\"/\")[-2])\n",
    "        np.save(save_save_dir, to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb06a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save thresholded\n",
    "if True:\n",
    "    if users_name == 'alina':\n",
    "        save_dir = \"/usr/xtmp/mammo/alina_code/shapesAL/data/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/OracleThresholdedImages/\"\n",
    "    elif users_name == 'vaibhav':\n",
    "        save_dir = \"/usr/xtmp/vs196/mammoproj/Code/ActiveLearning/AllOracleRuns/Run_\" + run_id + \"/Iter\" + str(iter_num) + \"/OracleThresholdedImages/\"\n",
    "    else:\n",
    "        print(\"wrong username\")\n",
    "        \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    else:\n",
    "        user_input = input(\"Do you want to overwrite this directory? Type y or yes to continue\")\n",
    "        if not (user_input==\"y\" or user_input==\"yes\"):\n",
    "            assert(False)\n",
    "            \n",
    "    threshold_and_save_images(saved_oracle_filepaths, oracle_results_thresholds, save_dir)\n",
    "    save_dir = convert_directory_to_floodfill(save_dir,iter0=False)\n",
    "    print(f\"Saved in {save_dir}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f74ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
